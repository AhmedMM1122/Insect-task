{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedMM1122/Insect-task/blob/main/Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEYV27JdAl3K"
      },
      "outputs": [],
      "source": [
        "#import Libraries\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import zscore\n",
        "import pandas as pd\n",
        "import time\n",
        "import scipy.special\n",
        "from scipy.special import gamma, gammaln\n",
        "from scipy.stats import mode\n",
        "from scipy.stats import mode\n",
        "from sklearn.preprocessing import StandardScaler,normalize\n",
        "from sklearn.decomposition import PCA\n",
        "import scipy.io\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "from scipy.linalg import block_diag\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z44tNpJqN-D5",
        "outputId": "13b532e6-9bd3-423d-9ba8-1b1326420b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "dataset = '/content/drive/MyDrive/INSECTS' #change this donia\n",
        "\n",
        "fname1 = f'/content/drive/MyDrive/INSECTS/data.mat' #change this donia\n",
        "fname2 = f'/content/drive/MyDrive/INSECTS/splits.mat'#change this donia\n",
        "\n",
        "data = scipy.io.loadmat(fname1)\n",
        "splits = scipy.io.loadmat(fname2)"
      ],
      "metadata": {
        "id": "6oAexBN1OIwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dna = data['embeddings_dna']\n",
        "embeddings_img = data['embeddings_img']\n",
        "labels = data['labels']\n",
        "trainval_loc = splits['trainval_loc']\n",
        "train_loc = splits['train_loc']\n",
        "test_seen_loc = splits['test_seen_loc']\n",
        "test_unseen_loc = splits['test_unseen_loc']\n",
        "val_seen_loc = splits['val_seen_loc']\n",
        "val_unseen_loc = splits['val_unseen_loc']\n",
        "G=data['G']"
      ],
      "metadata": {
        "id": "5DEEfjEoOqwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'OSBC_DNA'\n",
        "transductive = True"
      ],
      "metadata": {
        "id": "pzix0JJ9OZDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ridge_regression\n",
        "\n",
        "def ridge_regression(embeddings_dna, embeddings_img, data_subset, lambda_,va_l1,va_l2):\n",
        "    di = embeddings_img.shape[1]\n",
        "    st = data_subset\n",
        "    X = embeddings_img[st[va_l1], :].T\n",
        "    D = embeddings_dna[st[va_l2], :].T\n",
        "\n",
        "    DXT = np.dot(D, X.T)\n",
        "    V = np.dot(DXT, np.linalg.inv(np.dot(X, X.T) + rho * np.eye(di)))\n",
        "\n",
        "    return V"
      ],
      "metadata": {
        "id": "zzYKSTJAPSs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if transductive:\n",
        "  dd = embeddings_dna.shape[1]\n",
        "  di = embeddings_img.shape[1]\n",
        "  rho = 1\n",
        "  if model == 'OSBC_IMG':\n",
        "    print(\"Transductive model works well if the mapping is from Image to DNA,\")\n",
        "    print(\"Thus we automatically run this version!\")\n",
        "  model = 'OSBC_DIT'\n",
        "  st = np.concatenate((trainval_loc, test_unseen_loc, test_seen_loc), axis=1)\n",
        "  embeddings_dna = zscore(embeddings_dna, axis=0)\n",
        "  embeddings_img = zscore(embeddings_img, axis=0)\n",
        "  st = np.array(st).flatten()\n",
        "  valid_indices = (st >= 0) & (st < embeddings_img.shape[0])\n",
        "  valid_indices1 = (st >= 0) & (st < embeddings_dna.shape[0])\n",
        "  start_time = time.time()\n",
        "  V = ridge_regression(embeddings_dna, embeddings_img, st, rho,valid_indices,valid_indices1)\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print('Time took for learning map in transductive setup:', elapsed_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6J_DO1EOoVj",
        "outputId": "9e962c0e-d2cc-4a27-aba3-3b4029c815f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time took for learning map in transductive setup: 7.903415203094482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca_dim = 500"
      ],
      "metadata": {
        "id": "PwYpi5cIRNMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tuned_params(model):\n",
        " #We use the upper() method to convert the input model string to uppercase\n",
        "    model = model.upper()\n",
        " #We define the parameter sets OSBC_IMG, OSBC_DNA, OSBC_DIL, and OSBC_DIT as lists.\n",
        "    OSBC_IMG = [0.1, 10, 5 * pca_dim, 1]\n",
        "    OSBC_DNA = [0.1, 10, 25 * pca_dim, 0.5]\n",
        "    OSBC_DIL = [0.1, 10, 5 * pca_dim, 0.5]\n",
        "    OSBC_DIT = [0.1, 10, 25 * pca_dim, 0.5]\n",
        "#evluate model of data, if it is img,dna,.......\n",
        "    if model == 'OSBC_IMG':\n",
        "        data = OSBC_IMG\n",
        "    elif model == 'OSBC_DNA':\n",
        "        data = OSBC_DNA\n",
        "    elif model == 'OSBC_DIL':\n",
        "        data = OSBC_DIL\n",
        "    elif model == 'OSBC_DIT':\n",
        "        data = OSBC_DIT\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model name\")\n",
        "#The selected parameters are unpacked into k_0, k_1, m, and s, and these values are returned as a tuple\n",
        "    k_0, k_1, m, s = data\n",
        "    return k_0, k_1, m, s\n"
      ],
      "metadata": {
        "id": "EDskK4K9SW8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_0, k_1, m, s = load_tuned_params(model)"
      ],
      "metadata": {
        "id": "1mMvEsqhetbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuning = False"
      ],
      "metadata": {
        "id": "8oYHCiYm45i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_split(embeddings_dna, embeddings_img, labels, trainval_loc, train_loc, test_seen_loc, test_unseen_loc, val_seen_loc, val_unseen_loc, split_type, model):\n",
        "  if model == 'OSBC_IMG':\n",
        "    features = embeddings_img\n",
        "  else:\n",
        "    features = embeddings_dna\n",
        "\n",
        "  if split_type == 'tuning':\n",
        "    train_idx = train_loc\n",
        "    test_seen_idx = val_seen_loc\n",
        "    test_unseen_idx = val_unseen_loc\n",
        "  else:\n",
        "    train_idx = trainval_loc\n",
        "    test_seen_idx = test_seen_loc\n",
        "    test_unseen_idx = test_unseen_loc\n",
        "\n",
        "# Training data and labels\n",
        "  xtrain = features[train_idx, :]\n",
        "  ytrain = labels[train_idx]\n",
        "\n",
        "# Test data and labels, Seen and Unseen\n",
        "  valid_test_seen_idx = np.where(test_seen_idx < features.shape[0])\n",
        "  valid_test_seen_idx = valid_test_seen_idx[0]  # Access the first element of the tuple\n",
        "  xtest_seen = features[valid_test_seen_idx, :]\n",
        "  ytest_seen = labels[valid_test_seen_idx]\n",
        "\n",
        "  xtest_unseen = features[test_unseen_idx, :]\n",
        "  ytest_unseen = labels[test_unseen_idx]\n",
        "\n",
        "  return xtrain, ytrain, xtest_unseen, ytest_unseen, xtest_seen, ytest_seen\n"
      ],
      "metadata": {
        "id": "LjLAKLt-46XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr, y_tr, x_ts_us, y_ts_us, x_ts_s, y_ts_s = data_split(embeddings_dna, embeddings_img, labels, trainval_loc, train_loc, test_seen_loc,\n",
        "                                                          test_unseen_loc, val_seen_loc, val_unseen_loc, 'test', model);"
      ],
      "metadata": {
        "id": "mprpnEhJ57Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr = x_tr.reshape(-1, 500)  # Reshape to (19420, 500)\n",
        "y_tr = y_tr.reshape(-1, 19420)  # Reshape to (19420, 1)\n"
      ],
      "metadata": {
        "id": "1nW_ROE06aXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_tr = y_tr.reshape(-1, 1)  # Reshape to (19420, 1)"
      ],
      "metadata": {
        "id": "PcR0utnX6lsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ts_us = x_ts_us.reshape(-1, 500)  # Reshape to (8463, 500)\n",
        "y_ts_us = y_ts_us.reshape(-1, 8463)  # Reshape to (8463, 1)"
      ],
      "metadata": {
        "id": "lclQk6KM6odG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_ts_us = y_ts_us.reshape(-1, 1)  # Reshape to (8463, 1)"
      ],
      "metadata": {
        "id": "Go36EC7_6ryQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function of  calculates the prior mean and prior covarince in advance to feed in Bayesian classifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#takes Data (the data matrix) and labels (class labels) as input arguments.\n",
        "def calculate_priors(Data, labels):\n",
        "    _, dim = Data.shape\n",
        "    unique_labels = np.unique(labels)\n",
        "    num_classes = len(unique_labels)\n",
        "\n",
        "    scatters = np.zeros((dim, dim, num_classes))\n",
        "    class_means = np.zeros((num_classes, dim))\n",
        "\n",
        "    for j in range(num_classes):\n",
        "        class_data = Data[labels == unique_labels[j]]\n",
        "#We compute the covariance matrices for each class using np.cov.\n",
        "#The rowvar=False argument specifies that each column represents a variable\n",
        "        scatters[:, :, j] = np.cov(class_data, rowvar=False)\n",
        "        class_means[j, :] = np.mean(class_data, axis=0)\n",
        "#we calculate the overall scatter matrix as the mean of the per-class scatter matrices and the overall class mean as the mean of the class means.\n",
        "    scatter = np.mean(scatters, axis=2)\n",
        "    mu_0 = np.mean(class_means, axis=0)\n",
        "\n",
        "    return mu_0, scatter\n",
        "\n"
      ],
      "metadata": {
        "id": "Rqi0Qz_9BHEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data = np.random.rand(100, 5)  # Example data with 100 samples and 5 features\n",
        "labels = np.random.randint(0, 3, 100)  # Example labels (0, 1, or 2)\n",
        "\n",
        "# Call the calculate_priors function with your data and labels\n",
        "mu_0, scatter = calculate_priors(Data, labels)\n",
        "\n",
        "# Print the calculated priors and scatter matrix\n",
        "print(\"mu_0 (class means):\")\n",
        "print(mu_0)\n",
        "print(\"\\nScatter matrix:\")\n",
        "print(scatter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTLiOqqvHmw6",
        "outputId": "b30c8c2a-a2f4-4886-c851-cee4266d7150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mu_0 (class means):\n",
            "[0.47394215 0.5046783  0.50473543 0.48172866 0.50269231]\n",
            "\n",
            "Scatter matrix:\n",
            "[[ 0.08532919 -0.01285999  0.00104571 -0.00758387 -0.01562938]\n",
            " [-0.01285999  0.08467357  0.00144442  0.00102159 -0.00532703]\n",
            " [ 0.00104571  0.00144442  0.10136072 -0.01351641 -0.02305694]\n",
            " [-0.00758387  0.00102159 -0.01351641  0.07885946  0.00225154]\n",
            " [-0.01562938 -0.00532703 -0.02305694  0.00225154  0.08744304]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "if transductive:\n",
        "  #pca= 0 ,We use np.dot for matrix multiplication.\n",
        "    x_tr_g = np.dot(V, embeddings_img[trainval_loc[0], :].T)\n",
        "    x_tr_g = x_tr_g.T\n",
        "    #we concatenate arrays using np.concatenate.\n",
        "    x_tr = np.concatenate((x_tr, x_tr_g), axis=0)\n",
        "    y_tr = np.concatenate((y_tr, y_tr))\n",
        "\n",
        "# PCA for dimensionality reduction\n",
        "pca_dim = 0\n",
        "start_time = time.time()\n",
        "C = np.cov(x_tr, rowvar=False)\n",
        "#computes its eigenvalues and eigenvectors (vv)\n",
        "_, vv = np.linalg.eig(C)\n",
        "x_tr = np.dot(x_tr, vv[:, -pca_dim:])\n",
        "x_ts_s = np.dot(x_ts_s, vv[:, -pca_dim:])\n",
        "x_ts_us = np.dot(x_ts_us, vv[:, -pca_dim:])\n",
        "end_time = time.time()  # Record the end time\n",
        "\n",
        "# Calculate and print the time taken for PCA\n",
        "pca_time = end_time - start_time\n",
        "print(f\"Time for PCA: {pca_time} seconds\")\n",
        "print (embeddings_img[trainval_loc, :].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYBdqXvJbUoK",
        "outputId": "67975a06-c6e3-4d61-ba0f-879e40528dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for PCA: 1.8063132762908936 seconds\n",
            "(1, 19420, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "def hyperparameter_setting(params):\n",
        "    parser = argparse.ArgumentParser(description=\"Parse hyperparameters\")\n",
        "    dim = 500\n",
        "\n",
        "    # Default values for hyperparameters\n",
        "    default_k0 = 0.01\n",
        "    default_k1 = 10\n",
        "    default_m = 5 * dim\n",
        "    default_mu0 = 0\n",
        "    default_s = 1\n",
        "    default_iter = 1\n",
        "    default_pca = 0\n",
        "    default_scatter = 0\n",
        "    default_tuning = False\n",
        "\n",
        "    parser.add_argument('--kappa_0', type=float, default=default_k0)\n",
        "    parser.add_argument('--kappa_1', type=float, default=default_k1)\n",
        "    parser.add_argument('--cov_shape', type=float, default=default_m)\n",
        "    parser.add_argument('--prior_mean', type=float, default=default_mu0)\n",
        "    parser.add_argument('--prior_covscale', type=float, default=default_s)\n",
        "    parser.add_argument('--iter', type=int, default=default_iter)\n",
        "    parser.add_argument('--pca', type=int, default=default_pca)\n",
        "    parser.add_argument('--scatter', type=int, default=default_scatter)\n",
        "    parser.add_argument('--tuning', type=bool, default=default_tuning)\n",
        "\n",
        "    args = parser.parse_args(params)\n",
        "\n",
        "    k_0 = args.kappa_0\n",
        "    k_1 = args.kappa_1\n",
        "    m = args.cov_shape\n",
        "    num_iter = args.iter\n",
        "    pca_dim = args.pca\n",
        "    mu_0 = args.prior_mean\n",
        "    s = args.prior_covscale\n",
        "    scatter = args.scatter\n",
        "    tuning = args.tuning\n",
        "\n",
        "    if mu_0 == 0:\n",
        "        mu_0 = [0] * dim\n",
        "    elif scatter == 0:\n",
        "        scatter = [[1 if i == j else 0 for j in range(dim)] for i in range(dim)]\n",
        "\n",
        "    return k_0, k_1, m, mu_0, s, scatter, num_iter, pca_dim, tuning"
      ],
      "metadata": {
        "id": "7qi73bU6I0ZX"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    'kappa_0': k_0,\n",
        "    'kappa_1': k_1,\n",
        "    'cov_shape': m,\n",
        "    'prior_covscale': s,\n",
        "    'pca': pca_dim\n",
        "    # Add other parameters as needed\n",
        "}"
      ],
      "metadata": {
        "id": "xZShX0ghHBu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arg_list = [f'--{key} {value}' for key, value in parameters.items()]"
      ],
      "metadata": {
        "id": "UFLUsfmeJnOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arg_list = []\n",
        "for key, value in parameters.items():\n",
        "    arg_list.extend(['--' + key, str(value)])\n"
      ],
      "metadata": {
        "id": "FzEtuGz9J_aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_0, k_1, m, mu_0, s, scatter, num_iter, pca_dim, tuning = hyperparameter_setting(arg_list)"
      ],
      "metadata": {
        "id": "xJzlsXinJdKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#The ppd_derivation function appears to calculate class predictive statistics (such as covariances, means, and degrees of freedom)\n",
        "# for a dataset with class labels and genus labels\n",
        "def ppd_derivation(X, Y, G, Psi, mu0, m, k0, k1): #X -> The dataset, where each row represents a data point, and each column represents a feature.\n",
        "#Y -> Class labels for each data point in X.\n",
        "#G ->enus labels for each data point in X.\n",
        "#Psi -> Initial covariance matrix.\n",
        "#mu0 -> Initial mean vector.\n",
        "#m, k0, k1 -> Hyperparameters used in the calculations.\n",
        "    seenclasses = np.unique(Y)\n",
        "#Separates seen classes (those with class labels) from surrogate classes (those without class labels) based on the provided genus labels.\n",
        "    seengenera = G[seenclasses]\n",
        "    uyg = np.unique(G)\n",
        "    ct = len(uyg)\n",
        "    nc = len(seenclasses) + ct\n",
        "    n, d = X.shape\n",
        "#Sig_s -> Class predictive covariances for each class (seen and surrogate).\n",
        "#mu_s -> Class predictive means for each class.\n",
        "#v_s -> Class predictive degrees of freedom for each class.\n",
        "#class_id -> Class IDs indicating which class each set of statistics belongs to.\n",
        "#Sigmas -> Intermediate results for covariance calculations.\n",
        "    Sig_s = np.zeros((d, d, nc))\n",
        "    Sigmas = np.zeros((d, d, nc))\n",
        "    mu_s = np.zeros((nc, d))\n",
        "    v_s = np.zeros(nc)\n",
        "\n",
        "    uy = seenclasses\n",
        "    ncl = len(uy)\n",
        "    cnt = 0\n",
        "#For each seen class:\n",
        "\n",
        "#1-Computes class-specific statistics, including the number of points, mean, and scatter matrix.\n",
        "#2-Calculates class predictive statistics, taking into account data likelihood and global prior.\n",
        "    for i in range(ncl):\n",
        "        in_idx = Y == uy[i]\n",
        "        Xi = X[in_idx, :]\n",
        "\n",
        "        cur_n = np.sum(in_idx)\n",
        "        cur_S = (cur_n - 1) * np.cov(Xi, rowvar=False)\n",
        "        cur_mu = np.mean(Xi, axis=0)\n",
        "\n",
        "        v_s[cnt] = cur_n + m - d + 1\n",
        "        mu_s[cnt, :] = (cur_n * cur_mu + (k0 * k1 / (k0 + k1)) * mu0) / (cur_n + (k0 * k1 / (k0 + k1)))\n",
        "        Smu = ((cur_n * (k0 * k1 / (k0 + k1))) / ((k0 * k1 / (k0 + k1)) + cur_n)) * np.outer(cur_mu - mu0, cur_mu - mu0)\n",
        "        Sig_s[:, :, cnt] = (Psi + cur_S + Smu) / (((cur_n + (k0 * k1 / (k0 + k1))) * v_s[cnt]) / (cur_n + (k0 * k1 / (k0 + k1)) + 1))\n",
        "        cnt += 1\n",
        "\n",
        "    uy = np.unique(G)\n",
        "    ncl = len(uy)\n",
        "    class_id = np.zeros(nc)\n",
        "    cnt = 0\n",
        "\n",
        "    for i in range(ncl):\n",
        "        in_idx = np.zeros(n, dtype=bool)\n",
        "\n",
        "        genus = uy[i]\n",
        "        classes = seenclasses[seengenera == genus]\n",
        "        nci = len(classes)\n",
        "\n",
        "        if nci >= 1:\n",
        "#For each surrogate genus class:\n",
        "\n",
        "#Identifies the classes belonging to the genus.\n",
        "#Calculates component-specific statistics (means, scatter matrices, etc.) for the classes within the genus.\n",
        "#Computes genus-specific predictive statistics based on the component statistics.\n",
        "            for j in range(nci):\n",
        "                in_idx[Y == classes[j]] = True\n",
        "\n",
        "            Yi = Y[in_idx]\n",
        "            Xi = X[in_idx, :]\n",
        "            uyi = np.unique(Yi)\n",
        "\n",
        "            ncpi = len(uyi)\n",
        "            xkl = np.zeros((ncpi, d))\n",
        "            Skl = np.zeros((d, d, ncpi))\n",
        "            kap = np.zeros(ncpi)\n",
        "            nkl = np.zeros(ncpi)\n",
        "\n",
        "            for j in range(ncpi):\n",
        "                in_idx = Yi == uyi[j]\n",
        "                nkl[j] = np.sum(in_idx)\n",
        "                kap[j] = nkl[j] * k1 / (nkl[j] + k1)\n",
        "                Xij = Xi[in_idx, :]\n",
        "                xkl[j, :] = np.mean(Xij, axis=0)\n",
        "                Skl[:, :, j] = (nkl[j] - 1) * np.cov(Xij, rowvar=False)\n",
        "#Collects the computed class predictive statistics, class IDs, and intermediate results for all classes (both seen and surrogate)\n",
        "            sumkap = np.sum(kap)\n",
        "            kaps = (sumkap + k0) * k1 / (sumkap + k0 + k1)\n",
        "            sumSkl = np.sum(Skl, axis=2)\n",
        "            muk = (np.sum(xkl * (kap.reshape(-1, 1)), axis=0) + k0 * mu0) / (np.sum(kap) + k0)\n",
        "            vsc = np.sum(nkl) - ncpi + m - d + 1\n",
        "            class_id[cnt] = uy[i]\n",
        "            v_s[cnt] = vsc\n",
        "            Sigmas[:, :, cnt] = Psi + sumSkl\n",
        "            Sig_s[:, :, cnt] = (Psi + sumSkl) / ((kaps * v_s[cnt]) / (kaps + 1))\n",
        "            mu_s[cnt, :] = muk\n",
        "            cnt += 1\n",
        "\n",
        "    return Sig_s, mu_s, v_s, class_id, Sigmas\n"
      ],
      "metadata": {
        "id": "uYTkjQjSA6Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate example data\n",
        "X = np.random.rand(100, 5)  # Sample data with 100 samples and 5 features\n",
        "Y = np.random.randint(0, 3, 100)  # Class labels for 100 data points (3 classes)\n",
        "G = np.random.randint(0, 2, 100)  # Genus labels for 100 data points (2 genera)\n",
        "Psi = np.eye(5)  # Initial covariance matrix\n",
        "mu0 = np.zeros(5)  # Initial mean vector\n",
        "m = 2.0  # Hyperparameter m\n",
        "k0 = 0.5  # Hyperparameter k0\n",
        "k1 = 0.1  # Hyperparameter k1\n",
        "\n",
        "# Call the ppd_derivation function\n",
        "Sig_s, mu_s, v_s, class_id, Sigmas = ppd_derivation(X, Y, G, Psi, mu0, m, k0, k1)\n"
      ],
      "metadata": {
        "id": "ahW0oTSTcRKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.linalg  # Import scipy.linalg for Cholesky decomposition\n",
        "\n",
        "def predict(X, Sig_s, mu_s, v_s, class_id):\n",
        "    ncl, d = mu_s.shape\n",
        "    piconst = (d / 2) * np.log(np.pi)\n",
        "    gl_pc = scipy.special.gammaln(0.5 + np.arange(0.5, np.max(v_s) + d, 0.5))\n",
        "    n = X.shape[0]\n",
        "    prob_mat = np.zeros((n, ncl))\n",
        "\n",
        "    epsilon = 1e-4  # Small positive value for regularization\n",
        "\n",
        "    # Calculating log student-t likelihood for numerical stability\n",
        "    for j in range(ncl):\n",
        "        v = X - mu_s[j, :]  # Center the data\n",
        "\n",
        "        Sig_s_j = Sig_s[:, :, j] + epsilon * np.eye(d)  # Apply regularization\n",
        "\n",
        "        chsig = scipy.linalg.cholesky(Sig_s_j, lower=True)  # Cholesky decomposition\n",
        "        tpar = gl_pc[int(v_s[j] + d)] - (gl_pc[int(v_s[j])] + (d / 2) * np.log(int(v_s[j])) + piconst) - np.sum(np.log(np.diag(chsig)))  # Stu-t likelihood part 1\n",
        "        temp = scipy.linalg.solve_triangular(chsig, v.T, lower=True).T\n",
        "        prob_mat[:, j] = tpar - 0.5 * (v_s[j] + d) * np.log(1 + (1 / v_s[j]) * np.sum(temp * temp, axis=1))\n",
        "\n",
        "    bb = np.argmax(prob_mat, axis=1)\n",
        "    ypred = class_id[bb]  # To ensure labels are correctly assigned back to original ones\n",
        "\n",
        "    return ypred, prob_mat\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bbh4skBQE9n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.linalg\n",
        "\n",
        "# Sample data (replace with your actual data)\n",
        "X = np.random.rand(100, 2)  # Sample test data with 100 samples and 2 features\n",
        "ncl = 3  # Number of classes\n",
        "d = 2  # Number of features\n",
        "\n",
        "# Sample class-specific parameters (replace with your actual parameters)\n",
        "Sig_s = np.random.rand(d, d, ncl)  # Class predictive covariance matrices\n",
        "mu_s = np.random.rand(ncl, d)  # Class predictive means\n",
        "v_s = np.random.rand(ncl)  # Class predictive degrees of freedom\n",
        "class_id = np.arange(1, ncl + 1)  # Class IDs\n",
        "\n",
        "# Call the predict function with the sample data and parameters\n",
        "ypred, prob_mat = predict(X, Sig_s, mu_s, v_s, class_id)\n",
        "\n",
        "# Display the predicted labels and probability matrix\n",
        "print(\"Predicted Labels:\", ypred)\n",
        "print(\"Probability Matrix:\", prob_mat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uurJDtnCaI4G",
        "outputId": "e0d7c9ea-2f44-465f-d1e7-84434fc01adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Probability Matrix: [[inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]\n",
            " [inf inf inf]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-102-5eaa66e1c67d>:20: RuntimeWarning: divide by zero encountered in log\n",
            "  tpar = gl_pc[int(v_s[j] + d)] - (gl_pc[int(v_s[j])] + (d / 2) * np.log(int(v_s[j])) + piconst) - np.sum(np.log(np.diag(chsig)))  # Stu-t likelihood part 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eval1\n",
        "def evaluate(y_true, y_pred, G, mode):\n",
        "    # Implement your evaluation logic here\n",
        "    # Compute accuracy for each class\n",
        "    unique_classes = np.unique(G)\n",
        "    acc_per_class = []\n",
        "\n",
        "    for c in unique_classes:\n",
        "        class_indices = (G == c)\n",
        "        class_accuracy = np.mean(y_true[class_indices] == y_pred[class_indices])\n",
        "        acc_per_class.append(class_accuracy)\n",
        "\n",
        "    overall_accuracy = np.mean(y_true == y_pred)\n",
        "\n",
        "    return acc_per_class, overall_accuracy\n"
      ],
      "metadata": {
        "id": "eHz0S_dDdlMF"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eval2\n",
        "def evaluate(Y_true, Y_pred, G, class_type):\n",
        "    if class_type == 'unseen':\n",
        "        Y_true = G[Y_true]\n",
        "\n",
        "    uy = np.unique(Y_true)\n",
        "    nc = len(uy)\n",
        "    acc_per_class = np.zeros(nc)\n",
        "\n",
        "    for i in range(nc):\n",
        "        idx = Y_true == uy[i]\n",
        "        acc_per_class[i] = np.sum(Y_true[idx] == Y_pred[idx]) / np.sum(idx)\n",
        "\n",
        "    acc = np.mean(acc_per_class)\n",
        "\n",
        "    return acc_per_class, acc"
      ],
      "metadata": {
        "id": "ztvPkqHs-sNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define your input data and labels (replace with your actual data)\n",
        "y_true = np.array([0, 1, 1, 2, 2, 2, 3, 3, 4, 4])  # True class labels\n",
        "y_pred = np.array([0, 1, 1, 2, 3, 2, 3, 3, 4, 4])  # Predicted class labels\n",
        "G = np.array([0, 1, 1, 2, 2, 3, 3, 4, 4, 5])  # Genus labels\n",
        "mode = 'seen'  # Replace with your specific mode\n",
        "\n",
        "# Call the evaluate function\n",
        "acc_per_class, overall_accuracy = evaluate(y_true, y_pred, G, mode)\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy per Class:\")\n",
        "for i, acc in enumerate(acc_per_class):\n",
        "    print(f\"Class {i}: {acc * 100:.2f}%\")\n",
        "\n",
        "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "nus9ACNzqLUv",
        "outputId": "53219b51-2cdd-461d-c47c-d5e027e52bfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy per Class:\n",
            "Class 0: 100.00%\n",
            "Class 1: 100.00%\n",
            "Class 2: 50.00%\n",
            "Class 3: 100.00%\n",
            "Class 4: 100.00%\n",
            "Class 5: 100.00%\n",
            "Overall Accuracy: 90.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Donia\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Modify the Bayesian_cls function to accept keyword arguments\n",
        "def Bayesian_cls(x_tr, y_tr, x_ts_us, y_ts_us, x_ts_s, y_ts_s, G, **kwargs):\n",
        "    tic = time.time()\n",
        "\n",
        "    # Define default values for hyperparameters\n",
        "    default_value_for_kappa_0 = 1.0\n",
        "    default_value_for_kappa_1 = 1.0\n",
        "    default_value_for_cov_shape = 1.0\n",
        "    default_value_for_prior_mean = 0.0\n",
        "    default_value_for_prior_covscale = 1.0\n",
        "    default_value_for_scatter = 1.0\n",
        "    default_value_for_num_iter = 10\n",
        "    default_value_for_pca_dim = 0\n",
        "    default_value_for_tuning = True\n",
        "\n",
        "    # Extract hyperparameters from the kwargs dictionary with default values\n",
        "    k_0 = kwargs.get('kappa_0', default_value_for_kappa_0)\n",
        "    k_1 = kwargs.get('kappa_1', default_value_for_kappa_1)\n",
        "    m = kwargs.get('cov_shape', default_value_for_cov_shape)\n",
        "    mu_0 = kwargs.get('prior_mean', default_value_for_prior_mean)\n",
        "    s = kwargs.get('prior_covscale', default_value_for_prior_covscale)\n",
        "    scatter = kwargs.get('scatter', default_value_for_scatter)\n",
        "    num_iter = kwargs.get('num_iter', default_value_for_num_iter)\n",
        "    pca_dim = kwargs.get('pca', default_value_for_pca_dim)\n",
        "    tuning = kwargs.get('tuning', default_value_for_tuning)\n",
        "    # Rest of your function remains unchanged\n",
        "    # ...\n",
        "\n",
        "# Call the Bayesian_cls function with hyperparameters as keyword arguments\n",
        "\n",
        "\n",
        "    # Seen and unseen classes\n",
        "    tic = time.time()\n",
        "    d0 = x_tr.shape[1]\n",
        "\n",
        "    # Parsing passed parameters and hyperparameters from tuning\n",
        "    params = kwargs\n",
        "    k_0, k_1, m, mu_0, s, scatter, num_iter, pca_dim, tuning = hyperparameter_setting(params)\n",
        "\n",
        "    # num_iter for repeating the procedure several times to eliminate randomness\n",
        "    # You may change the # features to use by changing d0\n",
        "    if pca_dim:\n",
        "        # Dimensionality reduction from PCA\n",
        "        C = np.cov(x_tr, rowvar=False)\n",
        "        _, vv = np.linalg.eig(C)\n",
        "        x_tr = np.dot(x_tr, vv[:, -pca_dim:])\n",
        "        x_ts_s = np.dot(x_ts_s, vv[:, -pca_dim:])\n",
        "        x_ts_us = np.dot(x_ts_us, vv[:, -pca_dim:])\n",
        "\n",
        "        d0 = pca_dim\n",
        "\n",
        "    # Mixing feature positions\n",
        "    fin = []\n",
        "    if tuning:\n",
        "        for _ in range(num_iter):\n",
        "            fin.append(list(range(1, d0 + 1)))\n",
        "    else:\n",
        "        for _ in range(num_iter):\n",
        "            tmp = np.random.permutation(d0) + 1\n",
        "            fin.append(list(range(1, d0 + 1)))\n",
        "\n",
        "    # Main for loop for the calculations\n",
        "    for iter in range(len(fin)):\n",
        "        # training data\n",
        "        xn = x_tr[:, np.array(fin[iter]) - 1]\n",
        "        yn = y_tr\n",
        "        # Test data from seen and unseen classes (GZSL)\n",
        "        xt_unseen = x_ts_us[:, np.array(fin[iter]) - 1]\n",
        "        xt_seen = x_ts_s[:, np.array(fin[iter]) - 1]\n",
        "\n",
        "        # Pre-calculation of Psi (prior covariance) from tuned scale s, and scatter.\n",
        "        # The reason behind this if statement is that we don't want to repeat this precalculation\n",
        "        # in hypertuning since it is expensive in time but we want to calculate these values with new data during testing\n",
        "        if tuning:\n",
        "            Psi = (m - d0 - 1) * scatter / s\n",
        "        else:\n",
        "            mu_0, scatter = calculate_priors(xn, yn)\n",
        "            Psi = (m - d0 - 1) * scatter / s\n",
        "\n",
        "        # Class predictive cov, mean, and DoF\n",
        "        Sig_s, mu_s, v_s, class_id, Sigmas = ppd_derivation(xn, yn, G, Psi, mu_0, m, k_0, k_1)\n",
        "        toc = time.time()\n",
        "        model_time = toc - tic\n",
        "        print(f\"Model training time: {model_time}\")\n",
        "\n",
        "        # Inference phase\n",
        "        tic1 = time.time()\n",
        "        ypred_unseen[:, iter], prob_mat_us = predict(xt_unseen, Sig_s, mu_s, v_s, class_id)\n",
        "        ypred_seen[:, iter], prob_mat_s = predict(xt_seen, Sig_s, mu_s, v_s, class_id)\n",
        "        toc1 = time.time()\n",
        "        model_time1 = toc1 - tic1\n",
        "        print(f\"Model inference time: {model_time1}\")\n",
        "\n",
        "    # Performance calculation\n",
        "    # Mode of iterations to alleviate the effect of random variables\n",
        "    ypred_unseen_mode = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=ypred_unseen)\n",
        "    acc_per_usclass, unseen_acc = evaluate(y_ts_us, ypred_unseen_mode, G, 'unseen')  # Unseen classes\n",
        "\n",
        "    ypred_seen_mode = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=ypred_seen)\n",
        "    acc_per_sclass, seen_acc = evaluate(y_ts_s, ypred_seen_mode, G, 'seen')  # Seen classes\n",
        "\n",
        "    # Harmonic mean for seen and unseen classes accuracy\n",
        "    H = 2 * unseen_acc * seen_acc / (unseen_acc + seen_acc)\n",
        "\n",
        "    return seen_acc, unseen_acc, H, acc_per_sclass, acc_per_usclass, prob_mat_s, prob_mat_us, class_id\n",
        "\n"
      ],
      "metadata": {
        "id": "gNpadRoXl9fr"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define your hyperparameters\n",
        "hyperparameters = {\n",
        "    'kappa_0': 1.0,\n",
        "    'kappa_1': 1.0,\n",
        "    'cov_shape': 1.0,\n",
        "    'prior_mean': 0.0,\n",
        "    'prior_covscale': 1.0,\n",
        "    'scatter': 1.0,\n",
        "    'num_iter': 10,\n",
        "    'pca_dim': 0,\n",
        "    'tuning': True\n",
        "}\n",
        "\n",
        "# Call the Bayesian_cls function with hyperparameters as keyword arguments\n",
        "seen_acc, unseen_acc, H, s_cls_acc, us_cls_acc, pb_s, pb_us, class_id = Bayesian_cls(\n",
        "    x_tr, y_tr, x_ts_us, y_ts_us, x_ts_s, y_ts_s, G, **hyperparameters\n",
        ")\n"
      ],
      "metadata": {
        "id": "w2rjG9rnnJ6S",
        "outputId": "67419c39-670a-466c-8322-ae386f244f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-eca35a1b1866>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Call the Bayesian_cls function with hyperparameters as keyword arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m seen_acc, unseen_acc, H, s_cls_acc, us_cls_acc, pb_s, pb_us, class_id = Bayesian_cls(\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ts_us\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ts_us\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ts_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ts_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m )\n",
            "\u001b[0;31mTypeError\u001b[0m: Bayesian_cls() got an unexpected keyword argument 'kappa_0'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate fabricated data for demonstration\n",
        "np.random.seed(42)\n",
        "\n",
        "# Training data and labels\n",
        "x_tr = np.random.rand(100, 10)  # 100 samples, 10 features\n",
        "y_tr = np.random.randint(0, 10, 100)  # 100 labels, assuming 10 classes\n",
        "\n",
        "# Test data for unseen classes and labels\n",
        "x_ts_us = np.random.rand(50, 10)  # 50 samples for unseen classes\n",
        "y_ts_us = np.random.randint(10, 20, 50)  # 50 labels for unseen classes, assuming 10 unseen classes\n",
        "\n",
        "# Test data for seen classes and labels\n",
        "x_ts_s = np.random.rand(50, 10)  # 50 samples for seen classes\n",
        "y_ts_s = np.random.randint(0, 10, 50)  # 50 labels for seen classes, assuming 10 seen classes\n",
        "\n",
        "# Genus labels (assuming 10 genus labels)\n",
        "\n",
        "params = (0.1, 0.5, 100, 1.0, 0.2, 0.01, 10, 50, True)\n",
        "if params[-1]:\n",
        "    fin = [list(range(x_tr.shape[1]))] * params[-3]\n",
        "else:\n",
        "    fin = [np.random.permutation(x_tr.shape[1]).tolist()[:params[-3]] for _ in range(params[-3])]\n",
        "# Call the Bayesian_cls function with your fabricated data and hyperparameters\n",
        "seen_acc, unseen_acc, H, acc_per_sclass, acc_per_usclass = Bayesian_cls(x_tr, y_tr, x_ts_us, y_ts_us, x_ts_s, y_ts_s, G, *params)\n",
        "\n",
        "# Print the results\n",
        "print(\"Seen Accuracy:\", seen_acc)\n",
        "print(\"Unseen Accuracy:\", unseen_acc)\n",
        "print(\"Harmonic Mean (H):\", H)\n",
        "print(\"Accuracy per Seen Class:\", acc_per_sclass)\n",
        "print(\"Accuracy per Unseen Class:\", acc_per_usclass)\n"
      ],
      "metadata": {
        "id": "GH79fMVsv1zS",
        "outputId": "a7dd7641-d70d-4a68-fecd-9f4776d30548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training time:\n",
            "0.0008711814880371094\n",
            "Model inference time:\n",
            "0.00041103363037109375\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-7422e048533b>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Call the Bayesian_cls function with your fabricated data and hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mseen_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munseen_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_per_sclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_per_usclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesian_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ts_us\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ts_us\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ts_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ts_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Print the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-4bc31c9de36d>\u001b[0m in \u001b[0;36mBayesian_cls\u001b[0;34m(x_tr, y_tr, x_ts_us, y_ts_us, x_ts_s, y_ts_s, G, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Mode of iterations to alleviate the effect of random variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mypred_unseen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0macc_per_usclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munseen_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_ts_us\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unseen'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Unseen classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Accuracy calculation for seen classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-f0f8f8d77f63>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(y_true, y_pred, G, mode)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mclass_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mclass_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0macc_per_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 50 but corresponding boolean dimension is 100"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ahmed\n",
        "def Bayesian_cls(x_tr, y_tr, x_ts_us, y_ts_us, x_ts_s, y_ts_s, G,*Kwargs):\n",
        "    tic = time.time()\n",
        "\n",
        "    d0 = x_tr.shape[1]\n",
        "    default_value_for_kappa_0 = 1.0\n",
        "    default_value_for_kappa_1 = 1.0\n",
        "    default_value_for_cov_shape = 1.0\n",
        "    default_value_for_prior_mean = 0.0\n",
        "    default_value_for_prior_covscale = 1.0\n",
        "    default_value_for_scatter = 1.0\n",
        "    default_value_for_num_iter = 10\n",
        "    default_value_for_pca_dim = 0\n",
        "    default_value_for_tuning = True\n",
        "\n",
        "    # Extract hyperparameters from the kwargs dictionary with default values\n",
        "    k_0 = Kwargs.get('kappa_0', default_value_for_kappa_0)\n",
        "    k_1 = Kwargs.get('kappa_1', default_value_for_kappa_1)\n",
        "    m = Kwargs.get('cov_shape', default_value_for_cov_shape)\n",
        "    mu_0 = Kwargs.get('prior_mean', default_value_for_prior_mean)\n",
        "    s = Kwargs.get('prior_covscale', default_value_for_prior_covscale)\n",
        "    scatter = Kwargs.get('scatter', default_value_for_scatter)\n",
        "    num_iter =Kwargs.get('num_iter', default_value_for_num_iter)\n",
        "    pca_dim = Kwargs.get('pca', default_value_for_pca_dim)\n",
        "    tuning = Kwargs.get('tuning', default_value_for_tuning)\n",
        "    arg_list = []\n",
        "    for key, value in parameters.items():\n",
        "        arg_list.extend(['--' + key, str(value)])\n",
        "    k_0, k_1, m, mu_0, s, scatter, num_iter, pca_dim, tuning = hyperparameter_setting(arg_list)\n",
        "    if pca_dim:\n",
        "        # Dimensionality reduction from PCA\n",
        "        C = np.cov(xtrain, rowvar=False)\n",
        "        eigvals, eigvecs = np.linalg.eigh(C)\n",
        "        idx = np.argsort(eigvals)\n",
        "        eigvecs = eigvecs[:, idx[-pca_dim:]]\n",
        "        xtrain = np.dot(xtrain, eigvecs)\n",
        "        xtest_seen = np.dot(xtest_seen, eigvecs)\n",
        "        xtest_unseen = np.dot(xtest_unseen, eigvecs)\n",
        "\n",
        "        d0 = pca_dim\n",
        "\n",
        "    # Mixing feature positions\n",
        "    if tuning:\n",
        "        fin = [list(range(1, d0 + 1))] * num_iter\n",
        "    else:\n",
        "        fin = [np.random.permutation(d0) + 1 for _ in range(num_iter)]\n",
        "        num_iter = len(fin)  # Get the number of iterations\n",
        "    ypred_unseen = np.empty((x_ts_us.shape[0], num_iter), dtype=int)  # Initialize as empty arrays\n",
        "    ypred_seen = np.empty((x_ts_s.shape[0], num_iter), dtype=int)\n",
        "    for iter in range(len(fin)):\n",
        "\n",
        "        # training data\n",
        "        xn = x_tr[:, fin[iter] - 1]\n",
        "        yn = y_tr\n",
        "        # Test data from seen and unseen classes (GZSL)\n",
        "        xt_unseen = x_ts_us[:, fin[iter] - 1]\n",
        "        xt_seen = x_ts_s[:, fin[iter] - 1]\n",
        "\n",
        "        # Pre-calculation of Psi (prior covariance) from tuned scale s, and\n",
        "        # scatter. The reason behind this if statement is that we don't want\n",
        "        # to repeat this precalculation in hyper-tuning since it is expensive\n",
        "        # in time but we want to calculate these values with new data during\n",
        "        # testing\n",
        "        if tuning:\n",
        "            Psi = (m - d0 - 1) * scatter / s\n",
        "        else:\n",
        "            mu_0, scatter = calculate_priors(xn, yn)\n",
        "            Psi = (m - d0 - 1) * scatter / s\n",
        "\n",
        "        # Class predictive cov, mean, and DoF\n",
        "        Sig_s, mu_s, v_s, class_id, Sigmas = ppd_derivation(xn, yn, G, Psi, mu_0, m, k_0, k_1)\n",
        "        toc = time.time()\n",
        "        model_time = toc - tic\n",
        "        print(f\"Model training time {model_time}: \")\n",
        "\n",
        "\n",
        "        # Inference phase\n",
        "        tic1 = time.time()\n",
        "        ypred_unseen[:, iter], prob_mat_us = predict(xt_unseen, Sig_s, mu_s, v_s, class_id)\n",
        "        ypred_seen[:, iter], prob_mat_s = predict(xt_seen, Sig_s, mu_s, v_s, class_id)\n",
        "        toc1 = time.time()\n",
        "        model_time1 = toc1 - tic1\n",
        "        print(f\"Model inference time {model_time}: \")\n",
        "    ypred_unseen_mode = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=ypred_unseen)\n",
        "    acc_per_usclass, unseen_acc = evaluate(y_ts_us, ypred_unseen_mode, G, 'unseen')  # Unseen classes\n",
        "\n",
        "    ypred_seen_mode = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=ypred_seen)\n",
        "    acc_per_sclass, seen_acc = evaluate(y_ts_s, ypred_seen_mode, G, 'seen')  # Seen classes\n",
        "\n",
        "    H = 2 * unseen_acc * seen_acc / (unseen_acc + seen_acc)\n",
        "\n",
        "    return seen_acc, unseen_acc, H, acc_per_sclass, acc_per_usclass, prob_mat_s, prob_mat_us, class_id\n"
      ],
      "metadata": {
        "id": "1pKka23u_L-2"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seen_acc, unseen_acc, H, s_cls_acc, us_cls_acc, pb_s, pb_us, class_id = Bayesian_cls(x_tr, y_tr, x_ts_us, y_ts_us, x_ts_s, y_ts_s, G)"
      ],
      "metadata": {
        "id": "tG6wje26D2P1",
        "outputId": "8a81d992-fefc-46ba-e388-a7c3f7531471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-2a137279f0ff>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseen_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munseen_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_cls_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mus_cls_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb_us\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesian_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ts_us\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ts_us\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ts_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ts_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-77-08bd9ebbc6fe>\u001b[0m in \u001b[0;36mBayesian_cls\u001b[0;34m(x_tr, y_tr, x_ts_us, y_ts_us, x_ts_s, y_ts_s, G, *Kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Extract hyperparameters from the kwargs dictionary with default values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mk_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kappa_0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value_for_kappa_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mk_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kappa_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value_for_kappa_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cov_shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value_for_cov_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'get'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p2bU4Xa2XkhH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}