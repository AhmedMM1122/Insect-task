{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedMM1122/Insect-task/blob/main/Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SEYV27JdAl3K"
      },
      "outputs": [],
      "source": [
        "#import Libraries\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import zscore\n",
        "import pandas as pd\n",
        "import time\n",
        "import scipy.special\n",
        "from scipy.special import gamma, gammaln\n",
        "from scipy.stats import mode\n",
        "from scipy.stats import mode\n",
        "from sklearn.preprocessing import StandardScaler,normalize\n",
        "from sklearn.decomposition import PCA\n",
        "import scipy.io\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "from scipy.linalg import block_diag\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z44tNpJqN-D5",
        "outputId": "aca998f5-56bd-4c57-873c-9dafd002adea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "dataset = '/content/drive/MyDrive/INSECTS' #change this donia\n",
        "\n",
        "fname1 = f'/content/drive/MyDrive/INSECTS/data.mat' #change this donia\n",
        "fname2 = f'/content/drive/MyDrive/INSECTS/splits.mat'#change this donia\n",
        "\n",
        "data = scipy.io.loadmat(fname1)\n",
        "splits = scipy.io.loadmat(fname2)"
      ],
      "metadata": {
        "id": "6oAexBN1OIwd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dna = data['embeddings_dna']\n",
        "embeddings_img = data['embeddings_img']\n",
        "labels = data['labels']\n",
        "trainval_loc = splits['trainval_loc']\n",
        "train_loc = splits['train_loc']\n",
        "test_seen_loc = splits['test_seen_loc']\n",
        "test_unseen_loc = splits['test_unseen_loc']\n",
        "val_seen_loc = splits['val_seen_loc']\n",
        "val_unseen_loc = splits['val_unseen_loc']\n",
        "G=data['G']"
      ],
      "metadata": {
        "id": "5DEEfjEoOqwg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'OSBC_DNA'\n",
        "transductive = True"
      ],
      "metadata": {
        "id": "pzix0JJ9OZDY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ridge_regression\n",
        "\n",
        "def ridge_regression(embeddings_dna, embeddings_img, data_subset, lambda_,va_l1,va_l2):\n",
        "    di = embeddings_img.shape[1]\n",
        "    st = data_subset\n",
        "    X = embeddings_img[st[va_l1], :].T\n",
        "    D = embeddings_dna[st[va_l2], :].T\n",
        "\n",
        "    DXT = np.dot(D, X.T)\n",
        "    V = np.dot(DXT, np.linalg.inv(np.dot(X, X.T) + rho * np.eye(di)))\n",
        "\n",
        "    return V"
      ],
      "metadata": {
        "id": "zzYKSTJAPSs5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if transductive:\n",
        "  dd = embeddings_dna.shape[1]\n",
        "  di = embeddings_img.shape[1]\n",
        "  rho = 1\n",
        "  if model == 'OSBC_IMG':\n",
        "    print(\"Transductive model works well if the mapping is from Image to DNA,\")\n",
        "    print(\"Thus we automatically run this version!\")\n",
        "  model = 'OSBC_DIT'\n",
        "  st = np.concatenate((trainval_loc, test_unseen_loc, test_seen_loc), axis=1)\n",
        "  embeddings_dna = zscore(embeddings_dna, axis=0)\n",
        "  embeddings_img = zscore(embeddings_img, axis=0)\n",
        "  st = np.array(st).flatten()\n",
        "  valid_indices = (st >= 0) & (st < embeddings_img.shape[0])\n",
        "  valid_indices1 = (st >= 0) & (st < embeddings_dna.shape[0])\n",
        "  start_time = time.time()\n",
        "  V = ridge_regression(embeddings_dna, embeddings_img, st, rho,valid_indices,valid_indices1)\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print('Time took for learning map in transductive setup:', elapsed_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6J_DO1EOoVj",
        "outputId": "b780f7ab-1ff4-409d-eedc-abffa83b5b23"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time took for learning map in transductive setup: 12.343558073043823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca_dim = 500"
      ],
      "metadata": {
        "id": "PwYpi5cIRNMN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tuned_params(model):\n",
        " #We use the upper() method to convert the input model string to uppercase\n",
        "    model = model.upper()\n",
        " #We define the parameter sets OSBC_IMG, OSBC_DNA, OSBC_DIL, and OSBC_DIT as lists.\n",
        "    OSBC_IMG = [0.1, 10, 5 * pca_dim, 1]\n",
        "    OSBC_DNA = [0.1, 10, 25 * pca_dim, 0.5]\n",
        "    OSBC_DIL = [0.1, 10, 5 * pca_dim, 0.5]\n",
        "    OSBC_DIT = [0.1, 10, 25 * pca_dim, 0.5]\n",
        "#evluate model of data, if it is img,dna,.......\n",
        "    if model == 'OSBC_IMG':\n",
        "        data = OSBC_IMG\n",
        "    elif model == 'OSBC_DNA':\n",
        "        data = OSBC_DNA\n",
        "    elif model == 'OSBC_DIL':\n",
        "        data = OSBC_DIL\n",
        "    elif model == 'OSBC_DIT':\n",
        "        data = OSBC_DIT\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model name\")\n",
        "#The selected parameters are unpacked into k_0, k_1, m, and s, and these values are returned as a tuple\n",
        "    k_0, k_1, m, s = data\n",
        "    return k_0, k_1, m, s\n"
      ],
      "metadata": {
        "id": "EDskK4K9SW8K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_0, k_1, m, s = load_tuned_params(model)"
      ],
      "metadata": {
        "id": "1mMvEsqhetbw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuning = False"
      ],
      "metadata": {
        "id": "8oYHCiYm45i4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_split(embeddings_dna, embeddings_img, labels, trainval_loc, train_loc, test_seen_loc, test_unseen_loc, val_seen_loc, val_unseen_loc, split_type, model):\n",
        "  if model == 'OSBC_IMG':\n",
        "    features = embeddings_img\n",
        "  else:\n",
        "    features = embeddings_dna\n",
        "\n",
        "  if split_type == 'tuning':\n",
        "    train_idx = train_loc\n",
        "    test_seen_idx = val_seen_loc\n",
        "    test_unseen_idx = val_unseen_loc\n",
        "  else:\n",
        "    train_idx = trainval_loc\n",
        "    test_seen_idx = test_seen_loc\n",
        "    test_unseen_idx = test_unseen_loc\n",
        "\n",
        "# Training data and labels\n",
        "  xtrain = features[train_idx, :]\n",
        "  ytrain = labels[train_idx]\n",
        "\n",
        "# Test data and labels, Seen and Unseen\n",
        "  valid_test_seen_idx = np.where(test_seen_idx < features.shape[0])\n",
        "  valid_test_seen_idx = valid_test_seen_idx[0]  # Access the first element of the tuple\n",
        "  xtest_seen = features[valid_test_seen_idx, :]\n",
        "  ytest_seen = labels[valid_test_seen_idx]\n",
        "\n",
        "  xtest_unseen = features[test_unseen_idx, :]\n",
        "  ytest_unseen = labels[test_unseen_idx]\n",
        "\n",
        "  return xtrain, ytrain, xtest_unseen, ytest_unseen, xtest_seen, ytest_seen\n"
      ],
      "metadata": {
        "id": "LjLAKLt-46XX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr, y_tr, x_ts_us, y_ts_us, x_ts_s, y_ts_s = data_split(embeddings_dna, embeddings_img, labels, trainval_loc, train_loc, test_seen_loc,\n",
        "                                                          test_unseen_loc, val_seen_loc, val_unseen_loc, 'test', model);"
      ],
      "metadata": {
        "id": "mprpnEhJ57Xe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr = x_tr.reshape(-1, 500)  # Reshape to (19420, 500)\n",
        "y_tr = y_tr.reshape(-1, 19420)  # Reshape to (19420, 1)\n"
      ],
      "metadata": {
        "id": "1nW_ROE06aXl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_tr = y_tr.reshape(-1, 1)  # Reshape to (19420, 1)"
      ],
      "metadata": {
        "id": "PcR0utnX6lsW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ts_us = x_ts_us.reshape(-1, 500)  # Reshape to (8463, 500)\n",
        "y_ts_us = y_ts_us.reshape(-1, 8463)  # Reshape to (8463, 1)"
      ],
      "metadata": {
        "id": "lclQk6KM6odG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_ts_us = y_ts_us.reshape(-1, 1)  # Reshape to (8463, 1)"
      ],
      "metadata": {
        "id": "Go36EC7_6ryQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function of  calculates the prior mean and prior covarince in advance to feed in Bayesian classifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#takes Data (the data matrix) and labels (class labels) as input arguments.\n",
        "def calculate_priors(Data, labels):\n",
        "    _, dim = Data.shape\n",
        "    unique_labels = np.unique(labels)\n",
        "    num_classes = len(unique_labels)\n",
        "\n",
        "    scatters = np.zeros((dim, dim, num_classes))\n",
        "    class_means = np.zeros((num_classes, dim))\n",
        "\n",
        "    for j in range(num_classes):\n",
        "        class_data = Data[labels == unique_labels[j]]\n",
        "#We compute the covariance matrices for each class using np.cov.\n",
        "#The rowvar=False argument specifies that each column represents a variable\n",
        "        scatters[:, :, j] = np.cov(class_data, rowvar=False)\n",
        "        class_means[j, :] = np.mean(class_data, axis=0)\n",
        "#we calculate the overall scatter matrix as the mean of the per-class scatter matrices and the overall class mean as the mean of the class means.\n",
        "    scatter = np.mean(scatters, axis=2)\n",
        "    mu_0 = np.mean(class_means, axis=0)\n",
        "\n",
        "    return mu_0, scatter\n",
        "\n"
      ],
      "metadata": {
        "id": "Rqi0Qz_9BHEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data = np.random.rand(100, 5)  # Example data with 100 samples and 5 features\n",
        "labels = np.random.randint(0, 3, 100)  # Example labels (0, 1, or 2)\n",
        "\n",
        "# Call the calculate_priors function with your data and labels\n",
        "mu_0, scatter = calculate_priors(Data, labels)\n",
        "\n",
        "# Print the calculated priors and scatter matrix\n",
        "print(\"mu_0 (class means):\")\n",
        "print(mu_0)\n",
        "print(\"\\nScatter matrix:\")\n",
        "print(scatter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTLiOqqvHmw6",
        "outputId": "fc39f56e-14a7-4fb1-89fc-96abf1348b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mu_0 (class means):\n",
            "[0.50881256 0.49764941 0.47759555 0.43993443 0.49359455]\n",
            "\n",
            "Scatter matrix:\n",
            "[[ 0.08726868  0.01386446 -0.00262738  0.00605541  0.0046722 ]\n",
            " [ 0.01386446  0.09112498  0.01288512  0.01279908 -0.00125045]\n",
            " [-0.00262738  0.01288512  0.09956055  0.00506373  0.00422888]\n",
            " [ 0.00605541  0.01279908  0.00506373  0.0832308  -0.00395807]\n",
            " [ 0.0046722  -0.00125045  0.00422888 -0.00395807  0.0848382 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "if transductive:\n",
        "  #pca= 0 ,We use np.dot for matrix multiplication.\n",
        "    x_tr_g = np.dot(V, embeddings_img[trainval_loc[0], :].T)\n",
        "    x_tr_g = x_tr_g.T\n",
        "    #we concatenate arrays using np.concatenate.\n",
        "    x_tr = np.concatenate((x_tr, x_tr_g), axis=0)\n",
        "    y_tr = np.concatenate((y_tr, y_tr))\n",
        "\n",
        "# PCA for dimensionality reduction\n",
        "pca_dim = 0\n",
        "start_time = time.time()\n",
        "C = np.cov(x_tr, rowvar=False)\n",
        "#computes its eigenvalues and eigenvectors (vv)\n",
        "_, vv = np.linalg.eig(C)\n",
        "x_tr = np.dot(x_tr, vv[:, -pca_dim:])\n",
        "x_ts_s = np.dot(x_ts_s, vv[:, -pca_dim:])\n",
        "x_ts_us = np.dot(x_ts_us, vv[:, -pca_dim:])\n",
        "end_time = time.time()  # Record the end time\n",
        "\n",
        "# Calculate and print the time taken for PCA\n",
        "pca_time = end_time - start_time\n",
        "print(f\"Time for PCA: {pca_time} seconds\")\n",
        "print (embeddings_img[trainval_loc, :].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYBdqXvJbUoK",
        "outputId": "d0b412ee-499e-4b5c-d3a4-c084245eb82e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time for PCA: 2.914390802383423 seconds\n",
            "(1, 19420, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "def hyperparameter_setting(params):\n",
        "    parser = argparse.ArgumentParser(description=\"Parse hyperparameters\")\n",
        "    dim = 500\n",
        "\n",
        "    # Default values for hyperparameters\n",
        "    default_k0 = 0.01\n",
        "    default_k1 = 10\n",
        "    default_m = 5 * dim\n",
        "    default_mu0 = 0\n",
        "    default_s = 1\n",
        "    default_iter = 1\n",
        "    default_pca = 0\n",
        "    default_scatter = 0\n",
        "    default_tuning = False\n",
        "\n",
        "    parser.add_argument('--kappa_0', type=float, default=default_k0)\n",
        "    parser.add_argument('--kappa_1', type=float, default=default_k1)\n",
        "    parser.add_argument('--cov_shape', type=float, default=default_m)\n",
        "    parser.add_argument('--prior_mean', type=float, default=default_mu0)\n",
        "    parser.add_argument('--prior_covscale', type=float, default=default_s)\n",
        "    parser.add_argument('--iter', type=int, default=default_iter)\n",
        "    parser.add_argument('--pca', type=int, default=default_pca)\n",
        "    parser.add_argument('--scatter', type=int, default=default_scatter)\n",
        "    parser.add_argument('--tuning', type=bool, default=default_tuning)\n",
        "\n",
        "    args = parser.parse_args(params)\n",
        "\n",
        "    k_0 = args.kappa_0\n",
        "    k_1 = args.kappa_1\n",
        "    m = args.cov_shape\n",
        "    num_iter = args.iter\n",
        "    pca_dim = args.pca\n",
        "    mu_0 = args.prior_mean\n",
        "    s = args.prior_covscale\n",
        "    scatter = args.scatter\n",
        "    tuning = args.tuning\n",
        "\n",
        "    if mu_0 == 0:\n",
        "        mu_0 = [0] * dim\n",
        "    elif scatter == 0:\n",
        "        scatter = [[1 if i == j else 0 for j in range(dim)] for i in range(dim)]\n",
        "\n",
        "    return k_0, k_1, m, mu_0, s, scatter, num_iter, pca_dim, tuning"
      ],
      "metadata": {
        "id": "7qi73bU6I0ZX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    'kappa_0': k_0,\n",
        "    'kappa_1': k_1,\n",
        "    'cov_shape': m,\n",
        "    'prior_covscale': s,\n",
        "    'pca': pca_dim\n",
        "    # Add other parameters as needed\n",
        "}"
      ],
      "metadata": {
        "id": "xZShX0ghHBu3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arg_list = [f'--{key} {value}' for key, value in parameters.items()]"
      ],
      "metadata": {
        "id": "UFLUsfmeJnOf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arg_list = []\n",
        "for key, value in parameters.items():\n",
        "    arg_list.extend(['--' + key, str(value)])\n"
      ],
      "metadata": {
        "id": "FzEtuGz9J_aK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_0, k_1, m, mu_0, s, scatter, num_iter, pca_dim, tuning = hyperparameter_setting(arg_list)"
      ],
      "metadata": {
        "id": "xJzlsXinJdKm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#The ppd_derivation function appears to calculate class predictive statistics (such as covariances, means, and degrees of freedom)\n",
        "# for a dataset with class labels and genus labels\n",
        "def ppd_derivation(X, Y, G, Psi, mu0, m, k0, k1): #X -> The dataset, where each row represents a data point, and each column represents a feature.\n",
        "#Y -> Class labels for each data point in X.\n",
        "#G ->enus labels for each data point in X.\n",
        "#Psi -> Initial covariance matrix.\n",
        "#mu0 -> Initial mean vector.\n",
        "#m, k0, k1 -> Hyperparameters used in the calculations.\n",
        "    seenclasses = np.unique(Y)\n",
        "#Separates seen classes (those with class labels) from surrogate classes (those without class labels) based on the provided genus labels.\n",
        "    seengenera = G[seenclasses]\n",
        "    uyg = np.unique(G)\n",
        "    ct = len(uyg)\n",
        "    nc = len(seenclasses) + ct\n",
        "    n, d = X.shape\n",
        "#Sig_s -> Class predictive covariances for each class (seen and surrogate).\n",
        "#mu_s -> Class predictive means for each class.\n",
        "#v_s -> Class predictive degrees of freedom for each class.\n",
        "#class_id -> Class IDs indicating which class each set of statistics belongs to.\n",
        "#Sigmas -> Intermediate results for covariance calculations.\n",
        "    Sig_s = np.zeros((d, d, nc))\n",
        "    Sigmas = np.zeros((d, d, nc))\n",
        "    mu_s = np.zeros((nc, d))\n",
        "    v_s = np.zeros(nc)\n",
        "\n",
        "    uy = seenclasses\n",
        "    ncl = len(uy)\n",
        "    cnt = 0\n",
        "#For each seen class:\n",
        "\n",
        "#1-Computes class-specific statistics, including the number of points, mean, and scatter matrix.\n",
        "#2-Calculates class predictive statistics, taking into account data likelihood and global prior.\n",
        "    for i in range(ncl):\n",
        "        in_idx = Y == uy[i]\n",
        "        Xi = X[in_idx, :]\n",
        "\n",
        "        cur_n = np.sum(in_idx)\n",
        "        cur_S = (cur_n - 1) * np.cov(Xi, rowvar=False)\n",
        "        cur_mu = np.mean(Xi, axis=0)\n",
        "\n",
        "        v_s[cnt] = cur_n + m - d + 1\n",
        "        mu_s[cnt, :] = (cur_n * cur_mu + (k0 * k1 / (k0 + k1)) * mu0) / (cur_n + (k0 * k1 / (k0 + k1)))\n",
        "        Smu = ((cur_n * (k0 * k1 / (k0 + k1))) / ((k0 * k1 / (k0 + k1)) + cur_n)) * np.outer(cur_mu - mu0, cur_mu - mu0)\n",
        "        Sig_s[:, :, cnt] = (Psi + cur_S + Smu) / (((cur_n + (k0 * k1 / (k0 + k1))) * v_s[cnt]) / (cur_n + (k0 * k1 / (k0 + k1)) + 1))\n",
        "        cnt += 1\n",
        "\n",
        "    uy = np.unique(G)\n",
        "    ncl = len(uy)\n",
        "    class_id = np.zeros(nc)\n",
        "    cnt = 0\n",
        "\n",
        "    for i in range(ncl):\n",
        "        in_idx = np.zeros(n, dtype=bool)\n",
        "\n",
        "        genus = uy[i]\n",
        "        classes = seenclasses[seengenera == genus]\n",
        "        nci = len(classes)\n",
        "\n",
        "        if nci >= 1:\n",
        "#For each surrogate genus class:\n",
        "\n",
        "#Identifies the classes belonging to the genus.\n",
        "#Calculates component-specific statistics (means, scatter matrices, etc.) for the classes within the genus.\n",
        "#Computes genus-specific predictive statistics based on the component statistics.\n",
        "            for j in range(nci):\n",
        "                in_idx[Y == classes[j]] = True\n",
        "\n",
        "            Yi = Y[in_idx]\n",
        "            Xi = X[in_idx, :]\n",
        "            uyi = np.unique(Yi)\n",
        "\n",
        "            ncpi = len(uyi)\n",
        "            xkl = np.zeros((ncpi, d))\n",
        "            Skl = np.zeros((d, d, ncpi))\n",
        "            kap = np.zeros(ncpi)\n",
        "            nkl = np.zeros(ncpi)\n",
        "\n",
        "            for j in range(ncpi):\n",
        "                in_idx = Yi == uyi[j]\n",
        "                nkl[j] = np.sum(in_idx)\n",
        "                kap[j] = nkl[j] * k1 / (nkl[j] + k1)\n",
        "                Xij = Xi[in_idx, :]\n",
        "                xkl[j, :] = np.mean(Xij, axis=0)\n",
        "                Skl[:, :, j] = (nkl[j] - 1) * np.cov(Xij, rowvar=False)\n",
        "#Collects the computed class predictive statistics, class IDs, and intermediate results for all classes (both seen and surrogate)\n",
        "            sumkap = np.sum(kap)\n",
        "            kaps = (sumkap + k0) * k1 / (sumkap + k0 + k1)\n",
        "            sumSkl = np.sum(Skl, axis=2)\n",
        "            muk = (np.sum(xkl * (kap.reshape(-1, 1)), axis=0) + k0 * mu0) / (np.sum(kap) + k0)\n",
        "            vsc = np.sum(nkl) - ncpi + m - d + 1\n",
        "            class_id[cnt] = uy[i]\n",
        "            v_s[cnt] = vsc\n",
        "            Sigmas[:, :, cnt] = Psi + sumSkl\n",
        "            Sig_s[:, :, cnt] = (Psi + sumSkl) / ((kaps * v_s[cnt]) / (kaps + 1))\n",
        "            mu_s[cnt, :] = muk\n",
        "            cnt += 1\n",
        "\n",
        "    return Sig_s, mu_s, v_s, class_id, Sigmas\n"
      ],
      "metadata": {
        "id": "uYTkjQjSA6Bg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, Sig_s, mu_s, v_s, class_id):\n",
        "    ncl, d = mu_s.shape\n",
        "    piconst = (d / 2) * np.log(np.pi)\n",
        "    gl_pc = scipy.special.gammaln(0.5 + np.arange(0.5, max(v_s) + d, 0.5))\n",
        "    n = X.shape[0]\n",
        "    prob_mat = np.zeros((n, ncl))\n",
        "\n",
        "    # Calculating log student-t likelihood for numerical stability\n",
        "    for j in range(ncl):\n",
        "        v = X - mu_s[j, :]  # Center the data\n",
        "        chsig = np.linalg.cholesky(Sig_s[:, :, j])  # Cholesky decomposition\n",
        "        tpar = gl_pc[v_s[j] + d] - (gl_pc[v_s[j]] + (d / 2) * np.log(v_s[j]) + piconst) - np.sum(np.log(np.diag(chsig)))  # Stu-t lik part 1\n",
        "        temp = np.linalg.solve(chsig, v.T).T\n",
        "        prob_mat[:, j] = tpar - 0.5 * (v_s[j] + d) * np.log(1 + (1 / v_s[j]) * np.sum(temp * temp, axis=1))\n",
        "\n",
        "    bb = np.argmax(prob_mat, axis=1)\n",
        "    ypred = class_id[bb]  # To ensure labels are correctly assigned back to the original ones\n",
        "\n",
        "    return ypred, prob_mat"
      ],
      "metadata": {
        "id": "bbh4skBQE9n6"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize example values for X, Sig_s, mu_s, v_s, and class_id\n",
        "X = np.array([[1.0, 2.0], [2.0, 3.0], [3.0, 4.0]])  # Example data\n",
        "Sig_s = np.array([[[1.0, 0.0], [0.0, 1.0]], [[1.0, 0.0], [0.0, 1.0]]])  # Example covariance matrices\n",
        "mu_s = np.array([[1.0, 2.0], [3.0, 4.0]])  # Example means\n",
        "v_s = np.array([2.0, 3.0])  # Example v_s values\n",
        "class_id = np.array([0, 1])  # Example class IDs\n",
        "\n",
        "\n",
        "\n",
        "# Call the predict1 function with the example values\n",
        "ypred_unseen, prob_mat_us = predict(X, Sig_s, mu_s, v_s, class_id)\n",
        "\n",
        "# Print the results\n",
        "print(\"Predicted Class Labels:\", ypred_unseen)\n",
        "print(\"Probability Matrix:\")\n",
        "print(prob_mat_us)\n"
      ],
      "metadata": {
        "id": "yk8gbk5lFkJr",
        "outputId": "e31f8fb3-9548-457a-e7e1-1ec8ee1a8346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LinAlgError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-e79c9fbedf63>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Call the predict1 function with the example values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mypred_unseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_mat_us\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSig_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Print the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-30e8dc6c295e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(X, Sig_s, mu_s, v_s, class_id)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Center the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mchsig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSig_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Cholesky decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtpar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgl_pc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgl_pc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpiconst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchsig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Stu-t lik part 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchsig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_nonposdef\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Matrix is not positive definite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_eigenvalues_nonconvergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLinAlgError\u001b[0m: Matrix is not positive definite"
          ]
        }
      ]
    }
  ]
}